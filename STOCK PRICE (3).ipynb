{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85bfba3e-3680-42b4-9abf-185d56dcc661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475ac5e7-7a3c-42b8-a87a-9710ef2e83ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\tanmaya pradhan\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\tanmaya pradhan\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7eef8-52e2-4255-a65f-8f6f9ef5c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"apollo_data.xlsx\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb27a20-c12e-4c30-842c-50c4de983351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5fac2e-5e44-403c-91bc-eead19076565",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76557d-a5a9-4b5f-ab12-5d0782734904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"apollo_data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display basic info and first few rows\n",
    "df.info(), df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe67312-3735-467d-b765-140e1da59a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548bf10-2922-4be1-9cff-80b55a6d7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22946b52-a203-4877-932d-979313357a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum())\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9bfc5d-df33-44c6-adae-44c858843a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])  # Example for date conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5d373-9470-45f3-986b-6a40e3274424",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Deliverable Quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db1684-ca3b-4b71-9bc3-eace0a50802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d-%b-%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb73f72-988a-4f4d-acdc-ca3fa7f038f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f70d62-62b9-471c-bebb-161f6d46827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84026e3-93b3-426e-acae-8b08a52a596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.str.strip()  # Removes extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45930935-d6d4-4b1c-adbf-d8809adcf6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_cols = [col for col in columns if col not in df.columns]\n",
    "# print(\"Missing columns:\", missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315546bd-f657-41dd-b40f-2dd0654df3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())  # Shows first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41369c-27c7-4cd5-b7ff-9f47ae03396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())  # Shows first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ef4498-3f07-42c6-8a50-0ffb759d084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'No. of Shares'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a034e-47fc-48fa-b0d3-b628de13ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b5988e-3ffd-4743-9dfe-850de2ef55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3afc5-9410-41d2-b490-1fe5452f5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas scikit-learn openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d349b8-9a3e-4ad2-a91c-ae45c5344445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff9860-b381-41ce-9300-325d6579de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the Excel file\n",
    "# df = pd.read_excel(apollo_data.xlsx\")  # Ensure the file is in the same directory\n",
    "\n",
    "# # Display dataset with missing values\n",
    "# print(\"Dataset with Missing Values:\")\n",
    "# print(df.isnull().sum())  # Shows count of missing values per column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbbd03e-25da-4077-8fc2-a1de9d7d6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select multiple numerical columns for imputation\n",
    "columns_to_impute = [\"Deliverable Quantity\", \"% Deli. Qty to Traded Qty\"]  \n",
    "\n",
    "# Create an imputer with mean strategy\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Apply imputation only on the selected columns\n",
    "df[columns_to_impute] = imputer.fit_transform(df[columns_to_impute])\n",
    "\n",
    "# Display dataset after filling missing values\n",
    "print(\"\\nDataset After Filling Missing Values:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96c429-672a-4660-9f82-a0a63c564790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a3ae5-48c9-4c07-a958-a0d1f9799f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e48b5-3b95-41bb-8322-af54835b654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Check the updated format\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a631310-253e-4b6e-9ce6-1ed5fd50f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe684f79-2d9b-40c0-9707-d4d770dd3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5613ee4-4cc8-46af-8937-7549df207c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"Close Price\",axis=1)\n",
    "y = df[\"Close Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82217f40-82d6-444e-9340-85617df2ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df.drop(\"Total Turnover (Rs.)\",axis=1)\n",
    "n = df[\"Total Turnover (Rs.)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726fd6e9-d9ea-434d-aada-a98bf127cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7e19f-ab5a-4285-92bf-f576c47d5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49218a-5920-4ff7-a82a-21116160d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17eaa09-0790-4a16-bcdb-db3014286dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363eee4f-a5a4-4fcb-82a4-b998cee51048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "# df = pd.read_csv(\"stock_data.csv\")  # Replace with your actual file\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# List of columns to compare with 'Close Price'\n",
    "columns_to_plot = [\"Open Price\", \"High Price\", \"Low Price\", \"WAP\", \"No.of Shares\", \n",
    "                   \"No. of Trades\", \"Total Turnover (Rs.)\", \"Deliverable Quantity\", \n",
    "                   \"% Deli. Qty to Traded Qty\", \"Spread High-Low\", \"Spread Close-Open\"]\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, column in enumerate(columns_to_plot, 1):\n",
    "    plt.subplot(4, 3, i)  # Creating subplots (adjust layout if needed)\n",
    "    plt.scatter(df[column], df[\"Close Price\"], alpha=0.5, color=\"blue\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Close Price\")\n",
    "    plt.title(f\"Scatter Plot: {column} vs Close Price\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a74e2-b262-4322-900c-904fca4b4323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Display correlation values\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255a6b7-c2dd-461d-ac3f-ebb52100ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the heatmap of correlation\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Stock Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7045230-9f00-4fcc-a0de-c6e8d524f3e5",
   "metadata": {},
   "source": [
    "note :- \n",
    "    Open_Price, Close_Price, High_Price, Low_Price, WAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f4bc5-cf97-4b35-8b8c-fcafd5c36831",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldata = df[[\"Open Price\",\"Close Price\",\"High Price\",\"Low Price\",\"WAP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e584a39-2ea5-403c-a662-9105525a3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b82d67-ee08-495e-a6dd-b7d61bf99837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training (80%) and testing (20%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)  \n",
    "\n",
    "# Display shapes of datasets\n",
    "print(\"Training Set Shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing Set Shape:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e561a-31c8-4cf8-a822-b5e9ea7c80c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Load dataset (Replace with your actual file)\n",
    "# df = pd.read_csv(\"stock_data.csv\")  \n",
    "\n",
    "# Select numerical columns (excluding Date)\n",
    "num_cols = [\"Open Price\", \"High Price\", \"Low Price\", \"WAP\"]\n",
    "\n",
    "# Plot original distributions\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    sns.histplot(df[col], kde=True, bins=30, color=\"blue\")\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88623cbc-2c75-404a-9f6d-8901187afacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox, yeojohnson\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Load dataset\n",
    "# df = pd.read_csv(\"stock_data.csv\")  \n",
    "\n",
    "# Select numerical columns\n",
    "num_cols = [\"Open Price\", \"High Price\", \"Low Price\", \"WAP\"]\n",
    "\n",
    "# Copy dataset\n",
    "x_transformed = df[num_cols].copy()\n",
    "\n",
    "# Apply Power Transformation (Box-Cox for positive data, Yeo-Johnson otherwise)\n",
    "for col in num_cols:\n",
    "    if (df[col] > 0).all():  \n",
    "        # Box-Cox requires strictly positive values\n",
    "        x_transformed[col], _ = boxcox(df[col] + 1)\n",
    "    else:\n",
    "        # Yeo-Johnson works with positive and negative values\n",
    "        x_transformed[col], _ = yeojohnson(df[col] + 1)\n",
    "\n",
    "# Standardization (mean = 0, std = 1)\n",
    "x_standardized = (x_transformed - x_transformed.mean()) / x_transformed.std()\n",
    "\n",
    "# Plot Transformed Distributions\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(num_cols):\n",
    "    sns.histplot(x_standardized[col], kde=True, bins=30, ax=axes[i])\n",
    "    axes[i].set_title(f\"Transformed {col}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01e6aa-ab38-48a8-8b2b-8b32a7c10817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original distributions\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    sns.histplot( x_transformed[col], kde=True, bins=30, color=\"blue\")\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84a581-32b7-4c39-928a-32f946672e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649e0f3-fccd-4d68-acc7-7f60473177ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "163b28bc-6b9e-4eb2-acf6-fb8a7842aed2",
   "metadata": {},
   "source": [
    "## Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b5b7d-fdb1-4b41-abb4-c67d0db9cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726b80d-7df9-4a54-a148-7d1dfcad9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c316d2-bfda-49c1-83ca-983ae532b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset (Replace 'your_stock_data.csv' with actual filename)\n",
    "df = pd.read_excel(\"apollo_data.xlsx\")\n",
    "# Check for column names\n",
    "print(df.columns)\n",
    "\n",
    "# Ensure the correct column name for Close Price\n",
    "if \"Close Price\" in df.columns:\n",
    "    df.rename(columns={\"Close Price\": \"Close\"}, inplace=True)\n",
    "\n",
    "# Feature Engineering: Add Moving Averages & Price Change\n",
    "df[\"MA_10\"] = df[\"Close\"].rolling(window=10).mean()\n",
    "df[\"MA_50\"] = df[\"Close\"].rolling(window=50).mean()\n",
    "df[\"Price_Change\"] = df[\"Close\"].pct_change()\n",
    "\n",
    "# Drop NaN values caused by rolling window & pct_change\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=[\"Date\", \"Close\"])  # Drop Date & target column\n",
    "y = df[\"Close\"].values.reshape(-1, 1)  # Reshape for scaling\n",
    "\n",
    "# Split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Apply PowerTransformer (Yeo-Johnson transformation)\n",
    "pt_X = PowerTransformer(method=\"yeo-johnson\")\n",
    "X_train_scaled = pt_X.fit_transform(X_train)\n",
    "X_test_scaled = pt_X.transform(X_test)\n",
    "\n",
    "pt_y = PowerTransformer(method=\"yeo-johnson\")\n",
    "y_train_scaled = pt_y.fit_transform(y_train)\n",
    "y_test_scaled = pt_y.transform(y_test)\n",
    "\n",
    "# Convert scaled data back to DataFrame for easy handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "print(\" Data Scaling Completed Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7788a26-36bd-454a-b57b-4347c8f47610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train_scaled.ravel())  # Train RF\n",
    "\n",
    "rf_predictions = rf.predict(X_test_scaled)  # Predict\n",
    "rf_predictions_scaled = rf_predictions.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5198362-2fb4-4266-b4f5-822dca387ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bee240-4f7a-4125-8ece-4b0db90f2c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Train Random Forest Model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train_scaled.ravel())  # Training RF\n",
    "\n",
    "# Predict using Random Forest\n",
    "rf_predictions_train = rf.predict(X_train_scaled)\n",
    "rf_predictions_test = rf.predict(X_test_scaled)\n",
    "\n",
    "# Reshape predictions for scaling\n",
    "rf_predictions_train = rf_predictions_train.reshape(-1, 1)\n",
    "rf_predictions_test = rf_predictions_test.reshape(-1, 1)\n",
    "\n",
    "# Scale RF Predictions for LSTM input\n",
    "scaler_rf = MinMaxScaler(feature_range=(-1, 1))\n",
    "rf_predictions_train_scaled = scaler_rf.fit_transform(rf_predictions_train)\n",
    "rf_predictions_test_scaled = scaler_rf.transform(rf_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58d457-0564-426d-89dd-e8aacf5a8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare LSTM Input\n",
    "X_train_lstm = np.hstack((X_train_scaled, rf_predictions_train_scaled))\n",
    "X_test_lstm = np.hstack((X_test_scaled, rf_predictions_test_scaled))\n",
    "\n",
    "# Reshape input for LSTM (Samples, Time Steps, Features)\n",
    "X_train_lstm = X_train_lstm.reshape((X_train_lstm.shape[0], 1, X_train_lstm.shape[1]))\n",
    "X_test_lstm = X_test_lstm.reshape((X_test_lstm.shape[0], 1, X_test_lstm.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5858fd-1b9c-4f6c-bd34-427ec1b96b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(100, return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e321108-8b13-4e42-b000-8a9768a060ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train LSTM Model with Early Stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_lstm, y_train_scaled, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e229dc3e-c197-469f-b8fa-5930aaac2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Make Predictions with LSTM\n",
    "y_pred_lstm = model.predict(X_test_lstm)\n",
    "\n",
    "# Inverse Transform Predictions\n",
    "y_pred_lstm_original = pt_y.inverse_transform(y_pred_lstm)\n",
    "y_test_original = pt_y.inverse_transform(y_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17021b0d-dca1-4ad2-a709-3122b865e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate Model Performance\n",
    "rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_lstm_original))\n",
    "r2 = r2_score(y_test_original, y_pred_lstm_original)\n",
    "\n",
    "print(f\" Hybrid Model RMSE: {rmse}\")\n",
    "print(f\" Hybrid Model R²: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf05bd-7e0d-44b5-b5b9-528c0b2d2b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
